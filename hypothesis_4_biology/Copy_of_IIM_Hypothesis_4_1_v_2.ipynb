{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5RgYSvf3AZvK"
      },
      "outputs": [],
      "source": [
        "!pip install pymc arviz pandas matplotlib -q\n",
        "# --- The rest of your script is unchanged ---\n",
        "import pymc as pm\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Data Simulation with Structured Noise ---\n",
        "np.random.seed(42)\n",
        "n_gene_families = 20\n",
        "genes_per_family = 500\n",
        "\n",
        "base_proportions = np.array([0.70, 0.15, 0.15])\n",
        "observed_counts = np.zeros((n_gene_families, 3), dtype=int)\n",
        "\n",
        "for i in range(n_gene_families):\n",
        "    noise1 = np.random.normal(0, 0.02)\n",
        "    noise2 = -noise1 + np.random.normal(0, 0.005)\n",
        "    noise0 = np.random.normal(0, 0.01)\n",
        "    noisy_props = base_proportions + np.array([noise0, noise1, noise2])\n",
        "    noisy_props = np.abs(noisy_props)\n",
        "    noisy_props /= noisy_props.sum()\n",
        "    observed_counts[i, :] = np.random.multinomial(genes_per_family, noisy_props)\n",
        "\n",
        "print(\"--- Using Data with Anti-Correlated Fluctuation ---\")\n",
        "print(pd.DataFrame(observed_counts, columns=['Topology 1', 'Topology 2', 'Topology 3']).head())\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# --- 2. Define the Three Competing Models ---\n",
        "\n",
        "# MODEL 1: Standard Hierarchical ILS Model (Baseline)\n",
        "with pm.Model() as model_ils:\n",
        "    concentration = pm.Lognormal('concentration', mu=np.log(10), sigma=1, shape=3)\n",
        "    proportions = pm.Dirichlet('proportions', a=concentration, shape=(n_gene_families, 3))\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_ils = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "# MODEL 2: Refined IIM 2.0 \"Soft Constraint\" Model\n",
        "with pm.Model() as model_iim_refined:\n",
        "    mu_p0 = pm.Beta('mu_p0', alpha=7, beta=3)\n",
        "    kappa_p0 = pm.HalfNormal('kappa_p0', sigma=10)\n",
        "    p0 = pm.Beta('p0', alpha=mu_p0 * kappa_p0, beta=(1 - mu_p0) * kappa_p0, shape=n_gene_families)\n",
        "\n",
        "    remaining_prob = 1 - p0\n",
        "    kappa_minority = pm.HalfNormal('kappa_minority', sigma=20)\n",
        "    prop_p1 = pm.Beta('prop_p1', alpha=0.5 * kappa_minority, beta=0.5 * kappa_minority, shape=n_gene_families)\n",
        "\n",
        "    p1 = remaining_prob * prop_p1\n",
        "    p2 = remaining_prob * (1 - prop_p1)\n",
        "\n",
        "    proportions = pm.math.stack([p0, p1, p2], axis=1)\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_iim_refined = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "# MODEL 3: Advanced IIM 3.0 \"Correlated Fluctuation\" Model\n",
        "with pm.Model() as model_iim_correlated:\n",
        "    mu_logits = pm.Normal(\"mu_logits\", mu=0, sigma=1.5, shape=3)\n",
        "    sd_dist = pm.HalfNormal.dist(sigma=2.5, shape=3)\n",
        "    chol, corrs, stds = pm.LKJCholeskyCov(\"chol\", n=3, eta=2.0, sd_dist=sd_dist, compute_corr=True)\n",
        "    logits = pm.MvNormal(\"logits\", mu=mu_logits, chol=chol, shape=(n_gene_families, 3))\n",
        "    proportions = pm.Deterministic(\"proportions\", pm.math.softmax(logits, axis=1))\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_iim_correlated = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "\n",
        "# --- 4. The Final Model Showdown ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"           FINAL MODEL SHOWDOWN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_data = {\n",
        "    'Standard ILS': trace_ils,\n",
        "    'Refined IIM 2.0': trace_iim_refined,\n",
        "    'Advanced IIM 3.0 (Correlated)': trace_iim_correlated\n",
        "}\n",
        "compare_df = az.compare(comparison_data, ic='waic')\n",
        "print(compare_df)\n",
        "\n",
        "# --- 5. Examine the Correlation Parameter ---\n",
        "az.plot_posterior(trace_iim_correlated, var_names=[\"chol_corr\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUSK4d_5HSgd"
      },
      "outputs": [],
      "source": [
        "!pip install pymc arviz pandas matplotlib -q\n",
        "# --- The rest of your script is unchanged ---\n",
        "import pymc as pm\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Data Simulation with Structured Noise ---\n",
        "np.random.seed(42)\n",
        "n_gene_families = 20\n",
        "genes_per_family = 500\n",
        "\n",
        "base_proportions = np.array([0.70, 0.15, 0.15])\n",
        "observed_counts = np.zeros((n_gene_families, 3), dtype=int)\n",
        "\n",
        "for i in range(n_gene_families):\n",
        "    noise1 = np.random.normal(0, 0.02)\n",
        "    noise2 = -noise1 + np.random.normal(0, 0.005)\n",
        "    noise0 = np.random.normal(0, 0.01)\n",
        "    noisy_props = base_proportions + np.array([noise0, noise1, noise2])\n",
        "    noisy_props = np.abs(noisy_props)\n",
        "    noisy_props /= noisy_props.sum()\n",
        "    observed_counts[i, :] = np.random.multinomial(genes_per_family, noisy_props)\n",
        "\n",
        "print(\"--- Using Data with Anti-Correlated Fluctuation ---\")\n",
        "print(pd.DataFrame(observed_counts, columns=['Topology 1', 'Topology 2', 'Topology 3']).head())\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# --- 2. Define the Three Competing Models ---\n",
        "\n",
        "# MODEL 1: Standard Hierarchical ILS Model (Baseline)\n",
        "with pm.Model() as model_ils:\n",
        "    concentration = pm.Lognormal('concentration', mu=np.log(10), sigma=1, shape=3)\n",
        "    proportions = pm.Dirichlet('proportions', a=concentration, shape=(n_gene_families, 3))\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_ils = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "# MODEL 2: Refined IIM 2.0 \"Soft Constraint\" Model\n",
        "with pm.Model() as model_iim_refined:\n",
        "    mu_p0 = pm.Beta('mu_p0', alpha=7, beta=3)\n",
        "    kappa_p0 = pm.HalfNormal('kappa_p0', sigma=10)\n",
        "    p0 = pm.Beta('p0', alpha=mu_p0 * kappa_p0, beta=(1 - mu_p0) * kappa_p0, shape=n_gene_families)\n",
        "\n",
        "    remaining_prob = 1 - p0\n",
        "    kappa_minority = pm.HalfNormal('kappa_minority', sigma=20)\n",
        "    prop_p1 = pm.Beta('prop_p1', alpha=0.5 * kappa_minority, beta=0.5 * kappa_minority, shape=n_gene_families)\n",
        "\n",
        "    p1 = remaining_prob * prop_p1\n",
        "    p2 = remaining_prob * (1 - prop_p1)\n",
        "\n",
        "    proportions = pm.math.stack([p0, p1, p2], axis=1)\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_iim_refined = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "# MODEL 3: Advanced IIM 3.0 \"Correlated Fluctuation\" Model\n",
        "with pm.Model() as model_iim_correlated:\n",
        "    mu_logits = pm.Normal(\"mu_logits\", mu=0, sigma=1.5, shape=3)\n",
        "    sd_dist = pm.HalfNormal.dist(sigma=2.5, shape=3)\n",
        "    chol, corrs, stds = pm.LKJCholeskyCov(\"chol\", n=3, eta=2.0, sd_dist=sd_dist, compute_corr=True)\n",
        "    logits = pm.MvNormal(\"logits\", mu=mu_logits, chol=chol, shape=(n_gene_families, 3))\n",
        "    proportions = pm.Deterministic(\"proportions\", pm.math.softmax(logits, axis=1))\n",
        "    pm.Multinomial('obs', n=genes_per_family, p=proportions, observed=observed_counts, shape=(n_gene_families,3))\n",
        "    trace_iim_correlated = pm.sample(2000, tune=2500, chains=4, target_accept=0.99, idata_kwargs={'log_likelihood': True})\n",
        "\n",
        "\n",
        "# --- 4. The Final Model Showdown ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"           FINAL MODEL SHOWDOWN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_data = {\n",
        "    'Standard ILS': trace_ils,\n",
        "    'Refined IIM 2.0': trace_iim_refined,\n",
        "    'Advanced IIM 3.0 (Correlated)': trace_iim_correlated\n",
        "}\n",
        "compare_df = az.compare(comparison_data, ic='waic')\n",
        "print(compare_df)\n",
        "\n",
        "# --- 5. Examine the Correlation Parameter ---\n",
        "az.plot_posterior(trace_iim_correlated, var_names=[\"chol_corr\"])\n",
        "plt.show()\n",
        "\n",
        "# --- 6. Inspect the Winning Model's Parameters ---\n",
        "\n",
        "# Print the summary statistics for the correlated model's trace\n",
        "# This will show the mean values and narrow confidence intervals for the parameters\n",
        "summary = az.summary(trace_iim_correlated, var_names=[\"chol_corr\"])\n",
        "print(summary)\n",
        "\n",
        "# Plot the posterior using a histogram instead of a smooth curve\n",
        "# This avoids the KDE error and will visualize the result.\n",
        "az.plot_posterior(trace_iim_correlated, var_names=[\"chol_corr\"], kind='hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG7b4Fa7lIx-"
      },
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import matplotlib.pyplot as plt\n",
        "import xarray as xr\n",
        "\n",
        "# Observed counts\n",
        "observed_counts = np.array([11904, 2816, 2697])\n",
        "total_counts = observed_counts.sum()\n",
        "\n",
        "# Re-declare Standard ILS model and sample PPC\n",
        "with pm.Model() as model_set:\n",
        "    proportions = pm.Dirichlet('proportions', a=np.array([1, 1, 1]))\n",
        "    multinom_obs = pm.Multinomial('obs', n=total_counts, p=proportions, observed=observed_counts)\n",
        "    trace_set = pm.sample(1000, tune=1000, chains=2, cores=1) # Add sampling for trace_set\n",
        "    ppc_set = pm.sample_posterior_predictive(trace_set, var_names=[\"obs\"])\n",
        "\n",
        "\n",
        "# Re-declare IIM Correlated model and sample PPC\n",
        "with pm.Model() as model_iim_correlated:\n",
        "    mu_logits = pm.Normal(\"mu_logits\", mu=0, sigma=3.0, shape=3)\n",
        "    sd_dist = pm.HalfNormal.dist(sigma=3.0, shape=3)\n",
        "    chol, corrs, stds = pm.LKJCholeskyCov(\"chol\", n=3, eta=4.0, sd_dist=sd_dist, compute_corr=True)\n",
        "    logits = pm.MvNormal(\"logits\", mu=mu_logits, chol=chol, shape=3)\n",
        "    proportions_iim = pm.Deterministic(\"proportions\", pm.math.softmax(logits))\n",
        "    multinom_obs = pm.Multinomial('obs', n=total_counts, p=proportions_iim, observed=observed_counts)\n",
        "    trace_iim_correlated = pm.sample(1000, tune=1000, chains=2, cores=1) # Add sampling for trace_iim_correlated\n",
        "    ppc_iim = pm.sample_posterior_predictive(trace_iim_correlated, var_names=[\"obs\"])\n",
        "\n",
        "# DEBUG: Print available keys to verify\n",
        "print(\"Keys in ppc_set:\", ppc_set.keys())\n",
        "print(\"Keys in ppc_iim:\", ppc_iim.keys())\n",
        "\n",
        "# Grab the actual variable name that was sampled\n",
        "varname = list(ppc_set.keys())[0]  # Assuming only one variable returned\n",
        "\n",
        "# Build ArviZ InferenceData manually\n",
        "def build_ppc_idata(ppc_dict, varname):\n",
        "    # Extract the data array from the Dataset and reshape it\n",
        "    obs_samples = ppc_dict[varname].values.reshape(-1, observed_counts.shape[0])\n",
        "    return az.InferenceData(\n",
        "        posterior_predictive=xr.Dataset({\n",
        "            varname: ([\"draw\", \"obs_dim\"], obs_samples)\n",
        "        })\n",
        "    )\n",
        "\n",
        "# Build ID for plotting\n",
        "ppc_set_idata = build_ppc_idata(ppc_set, varname)\n",
        "ppc_iim_idata = build_ppc_idata(ppc_iim, varname)\n",
        "\n",
        "# Plot PPCs\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "az.plot_ppc(ppc_set_idata, ax=axes[0], kind='kde', observed=True)\n",
        "axes[0].set_title(\"PPC: Standard ILS\")\n",
        "\n",
        "az.plot_ppc(ppc_iim_idata, ax=axes[1], kind='kde', observed=True)\n",
        "axes[1].set_title(\"PPC: IIM 3.0 (Correlated)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}